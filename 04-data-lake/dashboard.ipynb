{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dashboard for analytic queries against Sparkify Date Lake\n",
    "\n",
    "Here is examples of possible analytic queries. You can create your own queries just using the Spark SQL syntax. Tables structure is described in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we should connect to the Data Warehouse (Amazon Redshift) and then we can answer on some analytical questions. \n",
    "> `CLUSTER` section of the configuration file `dwh.cfg` should be filled with Amazon Redshift cluster paramters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "DWH_ENDPOINT = config.get(\"CLUSTER\", \"HOST\")\n",
    "DWH_PORT = config.get(\"CLUSTER\", \"DB_PORT\")\n",
    "DWH_DB = config.get(\"CLUSTER\", \"DB_NAME\")\n",
    "DWH_DB_USER = config.get(\"CLUSTER\", \"DB_USER\")\n",
    "DWH_DB_PASSWORD = config.get(\"CLUSTER\", \"DB_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: sparkifydwhuser@sparkifydb'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT, DWH_DB)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('Sparkify Analytics') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.parquet('tables/songs/songs.parquet').createOrReplaceTempView('songs')\n",
    "spark.read.parquet('tables/artists/artists.parquet').createOrReplaceTempView('artists')\n",
    "spark.read.parquet('tables/users/users.parquet').createOrReplaceTempView('users')\n",
    "spark.read.parquet('tables/time/time.parquet').createOrReplaceTempView('time')\n",
    "spark.read.parquet('tables/songplays/songplays.parquet').createOrReplaceTempView('songplays')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find top 10 most popular songs\n",
    "\n",
    "Company want to publish top charts of songs. Find top 10 songs that users listened to most often. Print `song` (name of the song), `artist` and `play_count` (how many times users listened the song)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+----------+\n",
      "|          song|artist|play_count|\n",
      "+--------------+------+----------+\n",
      "|Setanta matins| Elena|         1|\n",
      "+--------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT s.title as song\n",
    "        , a.name as artist\n",
    "        , COUNT(*) as play_count\n",
    "    FROM songplays sp\n",
    "    INNER JOIN songs s ON s.song_id = sp.song_id\n",
    "    LEFT JOIN artists a ON a.artist_id = sp.artist_id\n",
    "    GROUP BY s.title, a.name\n",
    "    ORDER BY play_count DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekly statistics\n",
    "\n",
    "Build a report for each year, month and week to show how many songs were played and how many unique users uses Sparkify service. Report should contain following fields: `year`, `month`, `week`, `song_count` (how many songs were played), `user_count` (unique users which used the service at least once this month)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+----------+----------+\n",
      "|year|month|week|song_count|user_count|\n",
      "+----+-----+----+----------+----------+\n",
      "|2018|   11|  47|         1|         1|\n",
      "+----+-----+----+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT t.year\n",
    "        , t.month\n",
    "        , t.week\n",
    "        , COUNT(*) as song_count\n",
    "        , COUNT(DISTINCT sp.user_id) as user_count\n",
    "    FROM songplays sp\n",
    "    INNER JOIN time t ON t.start_time = sp.start_time\n",
    "    GROUP BY t.year, t.month, t.week\n",
    "    ORDER BY t.year ASC, t.month, t.week ASC\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
