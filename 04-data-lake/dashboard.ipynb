{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Dashboard for analytic queries against Sparkify Date Lake\n",
    "\n",
    "Here is examples of possible analytic queries. You can create your own queries just using the Spark SQL syntax. Tables structure is described in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "First we should setup credentials to S3 and then we can answer on some analytical questions. \n",
    "> `S3` section of the configuration file `dl.cfg` should be filled with user credentials with Full Access rights to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = config.get('S3', 'AWS_ACCESS_KEY_ID')\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = config.get('S3', 'AWS_SECRET_ACCESS_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('Sparkify Analytics') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.read.parquet('tables/songs/songs.parquet').createOrReplaceTempView('songs')\n",
    "spark.read.parquet('tables/artists/artists.parquet').createOrReplaceTempView('artists')\n",
    "spark.read.parquet('tables/users/users.parquet').createOrReplaceTempView('users')\n",
    "spark.read.parquet('tables/time/time.parquet').createOrReplaceTempView('time')\n",
    "spark.read.parquet('tables/songplays/songplays.parquet').createOrReplaceTempView('songplays')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Find top 10 most popular songs\n",
    "\n",
    "Company want to publish top charts of songs. Find top 10 songs that users listened to most often. Print `song` (name of the song), `artist` and `play_count` (how many times users listened the song).\n",
    "\n",
    "_(*): The output could contains a single row because of lack of real data. This is just an example of the posible query_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+----------+\n",
      "|          song|artist|play_count|\n",
      "+--------------+------+----------+\n",
      "|Setanta matins| Elena|         1|\n",
      "+--------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT s.title as song\n",
    "        , a.name as artist\n",
    "        , COUNT(*) as play_count\n",
    "    FROM songplays sp\n",
    "    INNER JOIN songs s ON s.song_id = sp.song_id\n",
    "    LEFT JOIN artists a ON a.artist_id = sp.artist_id\n",
    "    GROUP BY s.title, a.name\n",
    "    ORDER BY play_count DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Weekly statistics\n",
    "\n",
    "Build a report for each year, month and week to show how many songs were played and how many unique users uses Sparkify service. Report should contain following fields: `year`, `month`, `week`, `song_count` (how many songs were played), `user_count` (unique users which used the service at least once this month).\n",
    "\n",
    "_(*): The output could contains a single row because of lack of real data. This is just an example of the posible query_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+----------+----------+\n",
      "|year|month|week|song_count|user_count|\n",
      "+----+-----+----+----------+----------+\n",
      "|2018|   11|  47|         1|         1|\n",
      "+----+-----+----+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT t.year\n",
    "        , t.month\n",
    "        , t.week\n",
    "        , COUNT(*) as song_count\n",
    "        , COUNT(DISTINCT sp.user_id) as user_count\n",
    "    FROM songplays sp\n",
    "    INNER JOIN time t ON t.start_time = sp.start_time\n",
    "    GROUP BY t.year, t.month, t.week\n",
    "    ORDER BY t.year ASC, t.month, t.week ASC\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
