{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import udf, col, asc, desc, countDistinct\n",
    "from pyspark.sql.functions import date_format, row_number, monotonically_increasing_id \n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType, DoubleType, TimestampType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile as zf\n",
    "\n",
    "log_files = zf.ZipFile('data/log-data.zip', 'r')\n",
    "log_files.extractall('data/log_data')\n",
    "log_files.close()\n",
    "\n",
    "song_files = zf.ZipFile('data/song-data.zip', 'r')\n",
    "song_files.extractall('data')\n",
    "song_files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('DataLake') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "logDf = spark.read.json('data/log_data/*')\n",
    "songDf = spark.read.json('data/song_data/*/*/*/*')\n",
    "\n",
    "# logDf = spark \\\n",
    "#     .read \\\n",
    "#     .format('json') \\\n",
    "#     .option('inferSchema', 'true') \\\n",
    "#     .load('data/log_data/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+---------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|         artist_id|artist_latitude|artist_location|artist_longitude|         artist_name| duration|num_songs|           song_id|               title|year|\n",
      "+------------------+---------------+---------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|ARDR4AC1187FB371A1|           null|               |            null|Montserrat Caball...|511.16363|        1|SOBAYLL12A8C138AF9|Sono andati? Fing...|   0|\n",
      "+------------------+---------------+---------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "only showing top 1 row\n",
      "\n",
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songDf.show(1)\n",
    "songDf.count()\n",
    "songDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_schema = StructType([\n",
    "    StructField('song_id', StringType(), nullable=False),\n",
    "    StructField('title', StringType(), nullable=False),\n",
    "    StructField('artist_id', StringType(), nullable=True),\n",
    "    StructField('year', LongType(), nullable=True),\n",
    "    StructField('duration', DoubleType(), nullable=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_rdd = songDf \\\n",
    "    .filter(col('song_id').isNotNull()) \\\n",
    "    .filter(col('title').isNotNull()) \\\n",
    "    .select('song_id', 'title', 'artist_id', 'year', 'duration') \\\n",
    "    .dropDuplicates(['song_id']) \\\n",
    "    .rdd\n",
    "\n",
    "songs = spark.createDataFrame(songs_rdd, songs_schema)\n",
    "\n",
    "songs.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs \\\n",
    "    .write \\\n",
    "    .partitionBy('year', 'artist_id') \\\n",
    "    .mode('overwrite') \\\n",
    "    .parquet('tables/songs/songs.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOOLYAZ12A6701F4A6|Laws Patrolling (...|AREBBGV1187FB523D2|   0|173.66159|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      71|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_read = spark.read.parquet('tables/songs/songs.parquet')\n",
    "songs_read.createOrReplaceTempView('songs')\n",
    "spark.sql('SELECT * FROM songs WHERE title LIKE \"Law%\"').show()\n",
    "spark.sql('SELECT COUNT(*) FROM songs').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_schema = StructType([\n",
    "    StructField('artist_id', StringType(), nullable=False),\n",
    "    StructField('name', StringType(), nullable=False),\n",
    "    StructField('location', StringType(), nullable=True),\n",
    "    StructField('latitude', DoubleType(), nullable=True),\n",
    "    StructField('longitude', DoubleType(), nullable=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+-----------+--------+---------+\n",
      "|         artist_id|                name|   location|latitude|longitude|\n",
      "+------------------+--------------------+-----------+--------+---------+\n",
      "|ARDR4AC1187FB371A1|Montserrat Caball...|           |    null|     null|\n",
      "|AREBBGV1187FB523D2|Mike Jones (Featu...|Houston, TX|    null|     null|\n",
      "+------------------+--------------------+-----------+--------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists_rdd = songDf \\\n",
    "    .filter(col('artist_id').isNotNull()) \\\n",
    "    .filter(col('artist_name').isNotNull()) \\\n",
    "    .select('artist_id', 'artist_name', 'artist_location', 'artist_latitude', 'artist_longitude') \\\n",
    "    .rdd\n",
    "\n",
    "artists = spark.createDataFrame(artists_rdd, artists_schema)\n",
    "\n",
    "artists.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists.write.parquet('tables/artists/artists.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+-------------+------+-------------+--------------------+------+\n",
      "|  artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page|     registration|sessionId|         song|status|           ts|           userAgent|userId|\n",
      "+--------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+-------------+------+-------------+--------------------+------+\n",
      "|Harmonia|Logged In|     Ryan|     M|            0|   Smith|655.77751| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|Sehr kosmisch|   200|1542241826796|\"Mozilla/5.0 (X11...|    26|\n",
      "+--------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+-------------+------+-------------+--------------------+------+\n",
      "only showing top 1 row\n",
      "\n",
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logDf.show(1)\n",
    "logDf.count()\n",
    "logDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|    51|   17|\n",
      "|     7|    8|\n",
      "|    15|  495|\n",
      "|    54|   29|\n",
      "|   101|   73|\n",
      "|    11|    4|\n",
      "|    29|  381|\n",
      "|    69|   41|\n",
      "|    42|  149|\n",
      "|    73|  305|\n",
      "|    87|    2|\n",
      "|    64|    2|\n",
      "|     3|    3|\n",
      "|    30|  193|\n",
      "|    34|   14|\n",
      "|    59|    5|\n",
      "|     8|   37|\n",
      "|    28|    8|\n",
      "|    22|    2|\n",
      "|    85|  204|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logDf.count()\n",
    "logDf.groupBy('userId').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age| name|\n",
      "+---+-----+\n",
      "|  1|Alice|\n",
      "|  2|Alice|\n",
      "|  5|  Bob|\n",
      "+---+-----+\n",
      "\n",
      "+---+-----+---+\n",
      "|age| name| rn|\n",
      "+---+-----+---+\n",
      "|  5|  Bob|  1|\n",
      "|  2|Alice|  1|\n",
      "|  1|Alice|  2|\n",
      "+---+-----+---+\n",
      "\n",
      "+---+-----+\n",
      "|age| name|\n",
      "+---+-----+\n",
      "|  5|  Bob|\n",
      "|  1|Alice|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d = [\n",
    "    {'name': 'Alice', 'age': 1},\n",
    "    {'name': 'Alice', 'age': 2},\n",
    "    {'name': 'Bob', 'age': 5}\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(d)\n",
    "df.show()\n",
    "\n",
    "w = Window.partitionBy('name').orderBy(col('age').desc()).rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "df.withColumn('rn', row_number().over(w)).show()\n",
    "\n",
    "df.dropDuplicates(['name']).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_schema = StructType([\n",
    "    StructField('user_id', LongType(), nullable=False),\n",
    "    StructField('first_name', StringType(), nullable=True),\n",
    "    StructField('last_name', StringType(), nullable=True),\n",
    "    StructField('gender', StringType(), nullable=True),\n",
    "    StructField('level', StringType(), nullable=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     51|      Maia|    Burke|     F| free|\n",
      "|      7|    Adelyn|   Jordan|     F| free|\n",
      "+-------+----------+---------+------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_window = Window \\\n",
    "    .partitionBy('userId') \\\n",
    "    .orderBy(col('ts').desc()) \\\n",
    "    .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "users_rdd = logDf \\\n",
    "    .filter(col('page') == 'NextSong') \\\n",
    "    .filter(col('userId').isNotNull()) \\\n",
    "    .dropDuplicates(['userId']) \\\n",
    "    .withColumn('num', row_number().over(users_window)) \\\n",
    "    .withColumn('user_id', col('userId').cast(LongType())) \\\n",
    "    .filter(col('num') == 1) \\\n",
    "    .select('user_id', 'firstName', 'lastName', 'gender', 'level') \\\n",
    "    .rdd\n",
    "    \n",
    "users = spark.createDataFrame(users_rdd, users_schema)\n",
    "\n",
    "users.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.write.parquet('tables/users/users.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_schema = StructType([\n",
    "    StructField('start_time', TimestampType(), nullable=False),\n",
    "    StructField('hour', IntegerType(), nullable=False),\n",
    "    StructField('day', IntegerType(), nullable=False),\n",
    "    StructField('week', IntegerType(), nullable=False),\n",
    "    StructField('month', IntegerType(), nullable=False),\n",
    "    StructField('year', IntegerType(), nullable=False),\n",
    "    StructField('weekday', IntegerType(), nullable=False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|           ts|\n",
      "+-------------+\n",
      "|1542241826796|\n",
      "|1542242481796|\n",
      "|1542242741796|\n",
      "|1542247071796|\n",
      "|1542252577796|\n",
      "|1542253449796|\n",
      "|1542253460796|\n",
      "|1542260074796|\n",
      "|1542260277796|\n",
      "|1542260935796|\n",
      "+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logDf.select('ts').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|          start_time|hour|day|week|month|year|weekday|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|2018-11-15 16:12:...|  16| 15|  46|   11|2018|      3|\n",
      "|2018-11-21 06:18:...|   6| 21|  47|   11|2018|      3|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_rdd = logDf \\\n",
    "    .select('ts') \\\n",
    "    .withColumn('timestamp', (col('ts') / 1000).cast(TimestampType())) \\\n",
    "    .dropDuplicates(['timestamp']) \\\n",
    "    .select(\n",
    "        col('timestamp').alias('start_time'),\n",
    "        hour('timestamp').alias('hour'),\n",
    "        dayofmonth('timestamp').alias('day'),\n",
    "        weekofyear('timestamp').alias('week'),\n",
    "        month('timestamp').alias('month'),\n",
    "        year('timestamp').alias('year'),\n",
    "        date_format(col('timestamp'), 'F').cast(IntegerType()).alias('weekday')\n",
    "    ) \\\n",
    "    .rdd\n",
    "\n",
    "time = spark.createDataFrame(time_rdd, time_schema)\n",
    "\n",
    "time.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "time \\\n",
    "    .write \\\n",
    "    .partitionBy('year', 'month') \\\n",
    "    .mode('overwrite') \\\n",
    "    .parquet('tables/time/time.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "songplays_schema = StructType([\n",
    "    StructField('songplay_id', LongType(), nullable=False),\n",
    "    StructField('start_time', TimestampType(), nullable=False),\n",
    "    StructField('user_id', LongType(), nullable=False),\n",
    "    StructField('level', StringType(), nullable=True),\n",
    "    StructField('song_id', StringType(), nullable=False),\n",
    "    StructField('artist_id', StringType(), nullable=False),\n",
    "    StructField('session_id', LongType(), nullable=True),\n",
    "    StructField('location', StringType(), nullable=True),\n",
    "    StructField('user_agent', StringType(), nullable=True),\n",
    "    StructField('year', IntegerType(), nullable=False),\n",
    "    StructField('month', IntegerType(), nullable=False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "|songplay_id|          start_time|user_id|level|           song_id|         artist_id|session_id|            location|          user_agent|year|month|\n",
      "+-----------+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "|          1|2018-11-21 21:56:...|     15| paid|SOZCTXZ12AB0182364|AR5KOSW1187FB35FF4|       818|Chicago-Napervill...|\"Mozilla/5.0 (X11...|2018|   11|\n",
      "+-----------+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_logDf = logDf \\\n",
    "    .filter(col('page') == 'NextSong')\n",
    "\n",
    "clean_songDf = songDf \\\n",
    "    .filter(col('song_id').isNotNull()) \\\n",
    "    .filter(col('artist_id').isNotNull())\n",
    "\n",
    "songplays_rdd = clean_songDf \\\n",
    "    .join(clean_logDf,\n",
    "        (clean_songDf.title == clean_logDf.song)\n",
    "            & (clean_songDf.artist_name == clean_logDf.artist)\n",
    "            & (clean_songDf.duration == clean_logDf.length)\n",
    "        , 'inner') \\\n",
    "    .withColumn('id', monotonically_increasing_id() + 1) \\\n",
    "    .withColumn('start_time', (col('ts') / 1000).cast(TimestampType())) \\\n",
    "    .withColumn('user_id', col('userId').cast(LongType())) \\\n",
    "    .withColumn('year', year('start_time')) \\\n",
    "    .withColumn('month', month('start_time')) \\\n",
    "    .select(\n",
    "        'id'\n",
    "        , 'start_time'\n",
    "        , 'user_id'\n",
    "        , 'level'\n",
    "        , 'song_id'\n",
    "        , 'artist_id'\n",
    "        , 'sessionId'\n",
    "        , 'location'\n",
    "        , 'userAgent'\n",
    "        , 'year'\n",
    "        , 'month') \\\n",
    "    .repartition('year', 'month') \\\n",
    "    .rdd\n",
    "\n",
    "\n",
    "songplays = spark.createDataFrame(songplays_rdd, songplays_schema)\n",
    "\n",
    "songplays.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "songplays \\\n",
    "    .write \\\n",
    "    .partitionBy('year', 'month') \\\n",
    "    .mode('overwrite') \\\n",
    "    .parquet('tables/songplays/songplays.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
