{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Building Data Lake for demographic analysis and prediction in the U.S.\n",
    "\n",
    "## Data Engineering Capstone Project\n",
    "\n",
    "### Project Summary\n",
    "Main goal of the project is to building Data Lake for demographic analysis and prediction in the U.S.\n",
    "\n",
    "There are several datasets with raw data:\n",
    "\n",
    "* `I94 Immigration Data`;\n",
    "* `U.S. City Demographic Data`;\n",
    "* `Airport Codes`.\n",
    "\n",
    "Project focuses on creating data model for the future analysis and building ETL-pipeline using Apache Spark. The whole ETL-pipeline processes raw data, cleanup, apply data quality checks and store to the analytical area in the Data Lake according to data model.\n",
    "Resulting database allows analytics and data scientists to find and predict correlation between demographic situation in different cities/states and immigration to this locations.\n",
    "\n",
    "The project follows the follow steps:\n",
    "\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set pandas options\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create and configure Spark session. Add support for sas7bdat data format.\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .config('spark.jars.packages','saurfang:spark-sas7bdat:2.0.0-s_2.11')\n",
    "    .config('spark.sql.session.timeZone', 'UTC')\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope\n",
    "\n",
    "We will build a database (in the analytical area of our data lake) for demographic analysis and predictions which depends on immegration data.\n",
    "Our resulting database will have the following structure:\n",
    "\n",
    "* `airports` – dimension table which contains data about U.S. international airports. This table filled from the raw dataset represented by [airport-codes_csv.csv](./airport-codes_csv.csv) data source file.\n",
    "* `cities` – dimension table with U.S. cities that will interested us in the future analytics. This table filled from the raw dataset represented by [us-cities-demographics.json](./us-cities-demographics.json) datasource file. We want to analyze only data for the same cities to compare with aggregated data for the 2015 year.\n",
    "* `calendar` – dimension table with year and month to have a possibility to monitor situation with month granularity. This table filled from the raw dataset represented by `I94 Immigration Data` SAS database.\n",
    "* `immigration` – fact table which contains aggregated data grouped by year, month, and city. Each row of this table shows how much people (men, women and total) immgegrated to the particular U.S. city each month. This table filled from the raw dataset represented by `I94 Immigration Data` SAS database joined with `airports` and `cities` data.\n",
    "* `demographics` – pre-aggregated materialized view which is good candidate to land in data mart and contains aggregated data grouped by year and city. It can be used for the fast analytics and reporting. This table filled in two steps:\n",
    "  1. Filled from the `us-cities-demographics.csv` datasource file which already contains data for the 2015 year.\n",
    "  2. Filled from the `immigration` fact table by additition to the data for the previous years which allows us to see growth of the population.\n",
    "\n",
    "##### Important notes and assumptions\n",
    "\n",
    "1. We assume that all immigrants from the `I94 Immigration Data` will come and stay in the U.S. Actually we could analyze their visa types to be more precises, but for the scope of this project we will not consider it.\n",
    "2. We assume that all immigrants will stay for living in the city to which the airport belongs. In real life this may not be the case, but we will not consider it.\n",
    "3. Actually `demographics` table will contains data only for the 2015 and 2016 years because the `I94 Immigration Data` dataset contains data only for the 2016 year but our pipeliens will work for datasets with following years too.\n",
    "\n",
    "##### Tools\n",
    "\n",
    "We will use [Apache Spark](https://spark.apache.org/) to build our pipeline. Also we will use Data Lake idea to build our resulting tables and store our data in the HDFS or object storage like S3. We will not create staging area because in the Data Lake approache we can just load raw datasets with Spark, make all necessary transformations, cleanup the data, apply data quality checks and land it in the analytical area.\n",
    "\n",
    "#### Describe and Gather Data\n",
    "\n",
    "We will use several data sources to achieve our goal.\n",
    "\n",
    "1. We will use `U.S. City Demographic Data` grouped by city for 2015 year provided by [U.S. Census Bureau](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/information/).\n",
    "  * Data format: [JSON](https://en.wikipedia.org/wiki/JSON). You may see both JSON and CSV files with the same dataset in the repository, but we choose JSON format because we want to use different formats for each dataset.\n",
    "  * Data source: [us-cities-demographics.json](./us-cities-demographics.json)\n",
    "2. We will extract U.S. immigration data grouped by year, month and city from `I94 Immigration Data` provided by [US National Tourism and Trade Office](https://travel.trade.gov/research/reports/i94/historical/2016.html).\n",
    "  * Data format: [SAS7BDAT](https://cran.r-project.org/web/packages/sas7bdat/vignettes/sas7bdat.pdf)\n",
    "  * Data format description: SAS labels and possible values and errors described in the [I94_SAS_Labels_Descriptions.SAS](./I94_SAS_Labels_Descriptions.SAS) file.\n",
    "  * Data source: [i94_apr16_sub.sas7bdat](../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat). Actually there are bunch of files partitioned by month.\n",
    "3. Also we will use [Airport Code Table](https://datahub.io/core/airport-codes#data).\n",
    "  * Data format: [CSV](https://en.wikipedia.org/wiki/Comma-separated_values)\n",
    "  * Data source: [airport-codes_csv.csv](./airport-codes_csv.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### U.S. City Demographic Data\n",
    "\n",
    "Extract raw data from the data source and display few rows.\n",
    "\n",
    "As you may see in the example below demogrphic data stored in the `fields` column. There are several fields which we have to extract to achieve our goal:\n",
    "\n",
    "* city;\n",
    "* state;\n",
    "* state_code;\n",
    "* male_population;\n",
    "* female_population;\n",
    "* total_population;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datasetid</th>\n",
       "      <th>fields</th>\n",
       "      <th>record_timestamp</th>\n",
       "      <th>recordid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>us-cities-demographics</td>\n",
       "      <td>{'count': 2177650, 'city': 'Los Angeles', 'number_of_veterans': 85417, 'male_population': 1958998, 'foreign_born': 1485425, 'average_household_size': 2.86, 'median_age': 35.0, 'state': 'California', 'race': 'White', 'total_population': 3971896, 'state_code': 'CA', 'female_population': 2012898}</td>\n",
       "      <td>1970-01-01T03:00:00+03:00</td>\n",
       "      <td>7da42fda61238faccac3d43954a8f621a3a51194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us-cities-demographics</td>\n",
       "      <td>{'count': 124270, 'city': 'Metairie', 'number_of_veterans': 7187, 'male_population': 69515, 'foreign_born': 19871, 'average_household_size': 2.39, 'median_age': 41.6, 'state': 'Louisiana', 'race': 'White', 'total_population': 146458, 'state_code': 'LA', 'female_population': 76943}</td>\n",
       "      <td>1970-01-01T03:00:00+03:00</td>\n",
       "      <td>f176fd28e69ee0c152db080858781e769840c6cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>us-cities-demographics</td>\n",
       "      <td>{'count': 80781, 'city': 'Boca Raton', 'number_of_veterans': 4367, 'male_population': 44760, 'foreign_born': 21117, 'average_household_size': 2.22, 'median_age': 47.3, 'state': 'Florida', 'race': 'White', 'total_population': 93226, 'state_code': 'FL', 'female_population': 48466}</td>\n",
       "      <td>1970-01-01T03:00:00+03:00</td>\n",
       "      <td>ed4a94bf11b553ed8ebd93b7c24b0e8f326dadb0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>us-cities-demographics</td>\n",
       "      <td>{'count': 2566, 'city': 'Quincy', 'number_of_veterans': 4147, 'male_population': 44129, 'foreign_born': 32935, 'average_household_size': 2.39, 'median_age': 41.0, 'state': 'Massachusetts', 'race': 'Hispanic or Latino', 'total_population': 93629, 'state_code': 'MA', 'female_population': 49500}</td>\n",
       "      <td>1970-01-01T03:00:00+03:00</td>\n",
       "      <td>a4cd5f6782c79aa0348652718ca179ca390ce086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>us-cities-demographics</td>\n",
       "      <td>{'count': 16845, 'city': 'Union City', 'number_of_veterans': 1440, 'male_population': 38599, 'foreign_born': 32752, 'average_household_size': 3.46, 'median_age': 38.5, 'state': 'California', 'race': 'White', 'total_population': 74510, 'state_code': 'CA', 'female_population': 35911}</td>\n",
       "      <td>1970-01-01T03:00:00+03:00</td>\n",
       "      <td>b3b36950de605af92a78168f5127dff485a59b0b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                datasetid                                                                                                                                                                                                                                                                                                  fields           record_timestamp                                  recordid\n",
       "0  us-cities-demographics  {'count': 2177650, 'city': 'Los Angeles', 'number_of_veterans': 85417, 'male_population': 1958998, 'foreign_born': 1485425, 'average_household_size': 2.86, 'median_age': 35.0, 'state': 'California', 'race': 'White', 'total_population': 3971896, 'state_code': 'CA', 'female_population': 2012898}  1970-01-01T03:00:00+03:00  7da42fda61238faccac3d43954a8f621a3a51194\n",
       "1  us-cities-demographics               {'count': 124270, 'city': 'Metairie', 'number_of_veterans': 7187, 'male_population': 69515, 'foreign_born': 19871, 'average_household_size': 2.39, 'median_age': 41.6, 'state': 'Louisiana', 'race': 'White', 'total_population': 146458, 'state_code': 'LA', 'female_population': 76943}  1970-01-01T03:00:00+03:00  f176fd28e69ee0c152db080858781e769840c6cc\n",
       "2  us-cities-demographics                 {'count': 80781, 'city': 'Boca Raton', 'number_of_veterans': 4367, 'male_population': 44760, 'foreign_born': 21117, 'average_household_size': 2.22, 'median_age': 47.3, 'state': 'Florida', 'race': 'White', 'total_population': 93226, 'state_code': 'FL', 'female_population': 48466}  1970-01-01T03:00:00+03:00  ed4a94bf11b553ed8ebd93b7c24b0e8f326dadb0\n",
       "3  us-cities-demographics   {'count': 2566, 'city': 'Quincy', 'number_of_veterans': 4147, 'male_population': 44129, 'foreign_born': 32935, 'average_household_size': 2.39, 'median_age': 41.0, 'state': 'Massachusetts', 'race': 'Hispanic or Latino', 'total_population': 93629, 'state_code': 'MA', 'female_population': 49500}  1970-01-01T03:00:00+03:00  a4cd5f6782c79aa0348652718ca179ca390ce086\n",
       "4  us-cities-demographics              {'count': 16845, 'city': 'Union City', 'number_of_veterans': 1440, 'male_population': 38599, 'foreign_born': 32752, 'average_household_size': 3.46, 'median_age': 38.5, 'state': 'California', 'race': 'White', 'total_population': 74510, 'state_code': 'CA', 'female_population': 35911}  1970-01-01T03:00:00+03:00  b3b36950de605af92a78168f5127dff485a59b0b"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load raw data from the U.S. City Demographic Data and display first 5 rows\n",
    "demographics_source_file_name = './us-cities-demographics.json'\n",
    "demographics_demo_df = pd.read_json(demographics_source_file_name)\n",
    "demographics_demo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### I94 Immigration Data\n",
    "\n",
    "Extract raw data from the data source and display few rows.\n",
    "\n",
    "There are several fields which we have to extract to achieve our goal:\n",
    "\n",
    "* `cicid` – unique row identifier;\n",
    "* `i94yr` – year in 4 digit format;\n",
    "* `i94mon` – month index (Jan = 1, Feb = 2, Mar = 3, etc.);\n",
    "* `i94port` – airport code in 3 letters format described in the SAS file description;\n",
    "* `i94mode` – border crossing method (Air = 1, Sea = 2, Land = 3, Not reported = 9);\n",
    "* `i94addr` – U.S. state of arrival;\n",
    "* `gender` – male (M) or female (F)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load raw data from the I94 Immigration Data and display first 5 rows\n",
    "immigration_source_file_name = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "immigration_demo_df = pd.read_sas(immigration_source_file_name, 'sas7bdat', encoding='ISO-8859-1')\n",
    "immigration_demo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "df_spark.write.parquet(\"sas_data\")\n",
    "df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data\n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data\n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Write code here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    "\n",
    "Run Quality Checks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.3 Data dictionary\n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}